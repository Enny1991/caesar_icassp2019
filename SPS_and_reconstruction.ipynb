{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enea/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import es \n",
    "from utils import itd\n",
    "from utils import prob\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from python_speech_features import logfbank\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import re\n",
    "from scipy import stats\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "import gammamix\n",
    "\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import os\n",
    "import tables\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "import sys\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import seaborn as sns\n",
    "from spike_features import spike_count_features_by_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trigger(timestamps, addresses):\n",
    "    dx = 0.000001\n",
    "    idx =  np.argmax(np.diff(timestamps)/dx)\n",
    "    return timestamps[idx + 1:], addresses[idx + 1:]\n",
    "\n",
    "def wind_sp(ts, ch, w=0.005, limit=False, noise=False):\n",
    "    ts_int = (ts // w).astype('int32')\n",
    "    if len(ts_int) < 1:\n",
    "        ts_int = np.array([0,0])\n",
    "\n",
    "    A = np.zeros((np.max(ts_int) + 1, 64))\n",
    "    if noise:\n",
    "        A += np.abs(np.random.randn(A.shape[0], A.shape[1]))\n",
    "\n",
    "    for _t, _c in zip(ts_int, ch):\n",
    "        A[_t, _c] += 1\n",
    "        \n",
    "    if limit:\n",
    "        A = np.minimum(A, np.ones_like(A))\n",
    "    # returning [ch, T]\n",
    "    return A.T\n",
    "\n",
    "def wind_sp2(ts, ch, w=0.005, limit=False, noise=False):\n",
    "    ts -= np.min(ts)\n",
    "    ts_int = (ts // w).astype('int32')\n",
    "    if len(ts_int) < 1:\n",
    "        ts_int = np.array([0,0])\n",
    "\n",
    "    A = np.zeros((np.max(ts_int) + 1, 64))\n",
    "    if noise:\n",
    "        A += np.abs(np.random.randn(A.shape[0], A.shape[1]))\n",
    "\n",
    "    for _t, _c in zip(ts_int, ch):\n",
    "        A[_t, _c] += 1\n",
    "        \n",
    "    if limit:\n",
    "        A = np.minimum(A, np.ones_like(A))\n",
    "    # returning [ch, T]\n",
    "    return A.T\n",
    "\n",
    "def exp_feat(A, win=0.05, tpe='lap', l=300):\n",
    "    if tpe == 'exp':\n",
    "        t = np.arange(0, win, 0.001)\n",
    "        b = np.exp(-l * t)\n",
    "    elif tpe == 'lap':\n",
    "        t = np.arange(-win, win, 0.001)\n",
    "        b = np.exp(-l * np.abs(t))\n",
    "        \n",
    "    b /= np.linalg.norm(b)\n",
    "    AA = np.array([np.convolve(_a, b, 'same') for _a in A])\n",
    "    return AA\n",
    "\n",
    "def smear_fr(A, win=3, l=10):\n",
    "#     t = np.arange(-win, win, 1)\n",
    "#     b = np.exp(-l * np.abs(t))\n",
    "#     b = np.concatenate([np.arange(win), np.arange(win)[::-1]])\n",
    "#     A = np.array([np.convolve(_a, b, 'same') for _a in A.T])\n",
    "    A = gaussian_filter(A, 1)\n",
    "    return A\n",
    "\n",
    "def simple_low_pass(X, win=12, shift=8):\n",
    "#     X = np.concatenate([np.zeros((win, X.shape[1])),X , np.zeros((win, X.shape[1]))], 0)\n",
    "    n_win = (X.shape[0] - win) // shift\n",
    "    XX = np.zeros((n_win, X.shape[1]))\n",
    "    for i in range(0, n_win):\n",
    "        XX[i] = np.sum(X[i * shift: (i + 1) * shift] , 0) / win\n",
    "    return XX\n",
    "\n",
    "def spike_features(T1, C1, limit=False, noise=False):\n",
    "    A = wind_sp(np.array(T1), np.array(C1).astype('int32'), limit=limit, noise=noise)\n",
    "#     A = exp_feat(A, win=0.05, l=300, tpe='lap')\n",
    "    A = smear_fr(A, win=3)\n",
    "    A = np.log10(A + 1e-9)\n",
    "    A = simple_low_pass(A.T).T\n",
    "    return A\n",
    "\n",
    "def get_ctx_win(X, Y, ctx=5, shift=1):\n",
    "    n_win = (X.shape[1] - ctx * 2) // shift\n",
    "    X_re = np.array([X[:, i - ctx:i + ctx + 1].reshape(-1,) for i in range(ctx, n_win * shift, shift)])\n",
    "    Y_re = Y[:, ctx + 1:-(ctx * 2 - 1)].T\n",
    "    return X_re, Y_re\n",
    "\n",
    "\n",
    "def get_ctx_win2(X, Y, ctx=30, shift=1):\n",
    "    n_win = (X.shape[1] - ctx) // shift\n",
    "    X_re = np.array([X[:, i:i + ctx] for i in range(ctx, n_win * shift, shift)])\n",
    "    Y_re = np.array([Y[:, i:i + ctx] for i in range(ctx, n_win * shift, shift)])\n",
    "    return X_re.transpose(0, 2, 1), Y_re.transpose(0, 2, 1)\n",
    "\n",
    "\n",
    "def find_local_maxima(x, win=5):\n",
    "    to_pad = win // 2\n",
    "    x = np.pad(x, (to_pad,to_pad), 'constant', constant_values=(0, 0))\n",
    "    idx = []\n",
    "    for i in range(to_pad, len(x) - to_pad):\n",
    "        if np.argmax(x[i - to_pad: i + to_pad]) == to_pad:\n",
    "            idx.append(i - to_pad)\n",
    "    return np.array(idx)\n",
    "\n",
    "def correct_pos(pos):\n",
    "    if pos == 0:\n",
    "        pos = 1\n",
    "    if pos == 18:\n",
    "        pos = 17\n",
    "    return pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sps(idx, subset, sigma=20, channels=np.arange(64), adj=-1, verbose=False, fast=False):\n",
    "    \n",
    "    filename = basedir + 'aedat/{}/'.format(subset) + ALL_NAMES[subset][IDX] + '.aedat'\n",
    "    \n",
    "    # load / trigger / decode\n",
    "    timestamps, addresses = es.loadaerdat(filename)\n",
    "    timestamps, addresses = remove_trigger(timestamps, addresses)\n",
    "    timestamps, channel_id, ear_id, neuron_id, filterbank_id = es.decode_ams1c(timestamps, addresses, return_type=False)\n",
    "    neuron_id = neuron_id * 0\n",
    "    # load wavs\n",
    "    spk1, spk2, _ = re.compile('[0-9]+').split(ALL_NAMES[subset][IDX])\n",
    "    _, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "    \n",
    "    angles = ALL_ANGLES[subset][IDX].split(' ')\n",
    "    pos1, pos2 = int(float(angles[1])), int(float(angles[2]))\n",
    "    pos_dict = {0: 0, 30:1, 60:2, 90:3, 120:4, 150:5, 180:6}\n",
    "    pos = [pos_dict[pos1], pos_dict[pos2]]\n",
    "    if not fast:\n",
    "        fs, w1 = wavfile.read(basedir_wav + 'wavs/{}/'.format(subset) + GTS1[subset][IDX].replace('\\\\', '/') + '.wav')\n",
    "        fs, w2 = wavfile.read(basedir_wav + 'wavs/{}/'.format(subset) + GTS2[subset][IDX].replace('\\\\', '/') + '.wav')\n",
    "    else:\n",
    "        fs = w1 = w2 = 0\n",
    "    # get itd and fix them\n",
    "    total_evs = 0\n",
    "    _aa = {}\n",
    "    idx_dict = {}\n",
    "    for kk in channels:\n",
    "        indices_channels = np.isin(channel_id, np.array([kk]))\n",
    "        if kk in DICT_C:\n",
    "            try:\n",
    "                _itds, _itd_idx = itd.get_itds(timestamps[indices_channels], ear_id[indices_channels], neuron_id[indices_channels], save_to_file=None,\n",
    "                                     verbose=False, max_itd=max_itd, return_itd_indices=True)\n",
    "                idx_dict[kk] = _itd_idx\n",
    "                total_evs += len(_itds)\n",
    "                _mu = DICT_C[kk]['mu']\n",
    "                _corr = (_itds - _mu)\n",
    "                _aa[kk] = _corr\n",
    "            except Exception as e:\n",
    "                print e\n",
    "        else:\n",
    "            _itds, _itd_idx = itd.get_itds(timestamps[indices_channels], ear_id[indices_channels], neuron_id[indices_channels], save_to_file=None,\n",
    "                                     verbose=False, max_itd=max_itd, return_itd_indices=True)\n",
    "            _aa[kk] = _itds\n",
    "            idx_dict[kk] = _itd_idx\n",
    "            total_evs += len(_itds)\n",
    "\n",
    "    if verbose:\n",
    "        print \"#ENVS {} => RECOVERED {}\".format(len(timestamps), total_evs)\n",
    "    \n",
    "    # get probabilities\n",
    "    index_angles = np.vstack([np.arange(7), np.arange(0, 190, 30)]).T\n",
    "    num_angles = len(PRIORS)\n",
    "    initial_estimate = np.ones(num_angles) / num_angles # all angles are a priori equally likely\n",
    "    transition_probabilities = prob.get_transition_probabilities(index_angles, sigma=sigma) # gaussian a priori probability of itds given a certain position\n",
    "    itd_dict = itd.get_itd_dict(max_itd, num_bins) # array holding the mean values of all itd bins\n",
    "    \n",
    "    arg = {}\n",
    "    all_itds = []\n",
    "    for k, _a in _aa.iteritems():\n",
    "        estimates, argmax_estimates = prob.get_estimates(_a, initial_estimate, transition_probabilities, ITD_DICT, PRIORS)\n",
    "        arg[k] = argmax_estimates\n",
    "        all_itds.extend(_a)\n",
    "        \n",
    "    amax = []\n",
    "    for k, v in arg.iteritems():\n",
    "        amax.extend(v)\n",
    "    amax = np.array(amax)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"{} vs {}\".format(len(all_itds), len(amax))\n",
    "    # get separated spikes\n",
    "    T = []\n",
    "    C = []\n",
    "    adj = 1 if np.abs(pos[0] - pos[1]) > 2 else -1\n",
    "    \n",
    "    if verbose:\n",
    "        print adj\n",
    "    \n",
    "    for p in pos:\n",
    "        T1 = []\n",
    "        C1 = []\n",
    "        for ch in idx_dict.keys():\n",
    "            t = (timestamps[channel_id == ch])[idx_dict[ch][arg[ch] == p]]\n",
    "            T1.extend(t)\n",
    "            C1.extend(np.ones_like(t) * ch)\n",
    "            if adj > 0:\n",
    "                t = (timestamps[channel_id == ch])[idx_dict[ch][arg[ch] == p - 1]]\n",
    "                T1.extend(t)\n",
    "                C1.extend(np.ones_like(t) * ch)\n",
    "                t = (timestamps[channel_id == ch])[idx_dict[ch][arg[ch] == p + 1]]\n",
    "                T1.extend(t)\n",
    "                C1.extend(np.ones_like(t) * ch)\n",
    "        T.append(T1)\n",
    "        C.append(C1)\n",
    "    if verbose:\n",
    "        print \"#ENVS 1 {} ({})\".format(len(T[0]), len(C[0]))\n",
    "        print \"#ENVS 2 {} ({})\".format(len(T[1]), len(C[1]))\n",
    "    i0 = np.argsort(T[0])\n",
    "    i1 = np.argsort(T[1])\n",
    "    return [np.array(T[0])[i0],np.array(T[1])[i1]], [np.array(C[0])[i0].astype('int32'),np.array(C[1])[i1].astype('int32')], w1, w2, fs, amax, pos, timestamps, channel_id, ear_id\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "basedir = '/Data/DATASETS/CAESAR_TIDIGITS/aedat7/spikes_7_HV/'\n",
    "basedir_wav =  '/Data/DATASETS/CAESAR_TIDIGITS/'\n",
    "num_bins = 80\n",
    "max_itd = 800e-6\n",
    "num_channels = 64\n",
    "\n",
    "ALL_ANGLES = {}\n",
    "ALL_NAMES = {}\n",
    "\n",
    "GTS1 = {}\n",
    "GTS2 = {}\n",
    "\n",
    "with open(basedir + 'log_train.txt') as t:\n",
    "    ALL_ANGLES['train'] = [x for x in t.readlines()]\n",
    "\n",
    "with open(basedir + 'log_test.txt') as t:\n",
    "    ALL_ANGLES['test'] = [x for x in t.readlines()]\n",
    "\n",
    "with open('train_set.txt') as t:\n",
    "    ALL_NAMES['train'] = [line.split(' ')[4].strip() for line in t.readlines()]\n",
    "with open('train_set.txt') as t:\n",
    "    GTS1['train'] = [line.split(' ')[0].strip() for line in t.readlines()]\n",
    "with open('train_set.txt') as t:\n",
    "    GTS2['train'] = [line.split(' ')[1].strip() for line in t.readlines()]\n",
    "    \n",
    "with open('test_set.txt') as t:\n",
    "    ALL_NAMES['test'] = [line.split(' ')[4].strip() for line in t.readlines()]\n",
    "with open('test_set.txt') as t:\n",
    "    GTS1['test'] = [line.split(' ')[0].strip() for line in t.readlines()]\n",
    "with open('test_set.txt') as t:\n",
    "    GTS2['test'] = [line.split(' ')[1].strip() for line in t.readlines()]\n",
    "    \n",
    "PRIORS = np.load('priors_long_hv_mf_7_corrected_all.npy')\n",
    "DICT_C = pkl.load(open('correction_dict_mf_7.pkl', 'r'))\n",
    "ITD_DICT = itd.get_itd_dict(max_itd, num_bins) \n",
    "\n",
    "print len(PRIORS)\n",
    "\n",
    "# for subset in ['train', 'test']:\n",
    "#     for idx, l in enumerate(ALL_ANGLES[subset]):\n",
    "#         spk1, spk2, _ = re.compile('[0-9]+').split(l.split(' ')[0])\n",
    "#         pos1, pos2 = int(float(l.split(' ')[1]) // 10) , int(float(l.split(' ')[2]) // 10)\n",
    "#         pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "#         if np.abs(pos1 - pos2) > 2:\n",
    "#             VALID_IDX[subset].append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "SPK_DICT = {}\n",
    "\n",
    "count = 0\n",
    "with open('train_set.txt') as t:\n",
    "    s = [(line.split(' ')[0].strip(), line.split(' ')[0].strip()) for line in t.readlines()]\n",
    "    for i, (s1, s2) in enumerate(s):\n",
    "        k = s1.split('\\\\')[4].strip()\n",
    "        if k not in SPK_DICT:\n",
    "            SPK_DICT[k] = count\n",
    "            count += 1\n",
    "        k = s2.split('\\\\')[4].strip()\n",
    "        if k not in SPK_DICT:\n",
    "            SPK_DICT[k] = count\n",
    "            count += 1\n",
    "with open('test_set.txt') as t:\n",
    "    s = [(line.split(' ')[0].strip(), line.split(' ')[0].strip()) for line in t.readlines()]\n",
    "    for i, (s1, s2) in enumerate(s):\n",
    "        k = s1.split('\\\\')[4].strip()\n",
    "        if k not in SPK_DICT:\n",
    "            SPK_DICT[k] = count\n",
    "            count += 1\n",
    "        k = s2.split('\\\\')[4].strip()\n",
    "        if k not in SPK_DICT:\n",
    "            SPK_DICT[k] = count\n",
    "            count += 1\n",
    "\n",
    "print len(SPK_DICT.keys())\n",
    "\n",
    "ALL_SPK = {'train': {'s1': [], 's2': []}, 'test': {'s1': [], 's2': []}}\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    for idx, l in enumerate(ALL_ANGLES[subset]):\n",
    "        spk1, spk2, _ = re.compile('[0-9]+').split(l.split(' ')[0])\n",
    "        ALL_SPK[subset]['s1'].append(SPK_DICT[spk1])\n",
    "        ALL_SPK[subset]['s2'].append(SPK_DICT[spk2])\n",
    "\n",
    "ALL_LBL = {'train': [], 'test': []}\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    for i in range(len(ALL_NAMES[subset])):\n",
    "        ALL_LBL[subset].append(ALL_SPK[subset]['s1'][i])\n",
    "        ALL_LBL[subset].append(ALL_SPK[subset]['s2'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 37\n",
    "subset = 'train'\n",
    "\n",
    "ch = np.arange(0,64)\n",
    "T, C, w1, w2, fs, amax, pos, t, c, e = sps(IDX, subset, sigma=3, channels=ch)\n",
    "spkf1 = wind_sp2(T[0], C[0], limit=False, noise=False).T\n",
    "spkf2 = wind_sp2(T[1], C[1], limit=False, noise=False).T\n",
    "print spkf1.shape\n",
    "# i0 = np.argsort(T[0])\n",
    "# i1 = np.argsort(T[1])\n",
    "\n",
    "# print len(T[1])\n",
    "# print len(C[1])\n",
    "\n",
    "# spkf1 = spike_count_features_by_time(np.array(T[0])[i0], np.array(C[0])[i0].astype('int32'))\n",
    "# spkf2 = spike_count_features_by_time(np.array(T[1])[i1], np.array(C[1])[i1].astype('int32'))\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(2, 2,figsize=(20, 5))\n",
    "\n",
    "for spkf, k, w in zip([spkf1, spkf2], range(2), [w1, w2]):\n",
    "    \n",
    "    Y = logfbank(w, fs, nfft=2048,winlen=0.06,winstep=0.04)\n",
    "    ax[0][k].imshow(Y.T, aspect='auto')\n",
    "    ax[1][k].imshow(spkf.T / (np.std(spkf.T, 1, keepdims=True) + 1e-8), aspect='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check precision in localization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()\n",
    "acc = 0.\n",
    "count = 0.\n",
    "for IDX in tqdm(range(5999)):\n",
    "    pos1, pos2 = int(float(all_angles[IDX].split(' ')[1]) // 10) , int(float(all_angles[IDX].split(' ')[2]) // 10)\n",
    "#     if pos1 != pos2: \n",
    "    if np.abs(pos1 - pos2) >= 2:  # non-adiacent or same spot\n",
    "        p = np.sort([correct_pos(pos1), correct_pos(pos2)])\n",
    "        ch = np.arange(15,30)\n",
    "        T, C, w1, w2, fs, amax = sps(basedir + 'aedat/train/' + all_train[IDX] + '.aedat', sigma=5, channels=ch)\n",
    "        a = np.histogram(amax, 19, range=[0, 18], normed=True)\n",
    "        ii = find_local_maxima(a[0])\n",
    "        \n",
    "        kk = np.sort(ii[np.argsort(a[0][ii])[::-1][:2]])\n",
    "        if len(kk) == 2:\n",
    "            if np.abs(p[0] - kk[0]) <= 1 and np.abs(p[1] - kk[1]) <= 1:\n",
    "                acc += 1.\n",
    "            count += 1.\n",
    "print acc / count * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many are same position or adiacent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()\n",
    "idx_0_train = []\n",
    "idx_1_train = []\n",
    "idx_0_test = []\n",
    "idx_1_test = []\n",
    "acc = 0.\n",
    "count = 0.\n",
    "for IDX in range(1999):\n",
    "    pos1, pos2 = int(float(all_angles_test[IDX].split(' ')[1]) // 10) , int(float(all_angles_test[IDX].split(' ')[2]) // 10)\n",
    "    pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "    if pos1 == pos2:\n",
    "        count += 1.\n",
    "        idx_0_test.append(IDX)\n",
    "\n",
    "print \"TEST: same angle in {:.2} % of the cases ({})\".format(count / 1999 * 100, len(idx_0_test))\n",
    "\n",
    "count = 0.\n",
    "for IDX in range(5999):\n",
    "    pos1, pos2 = int(float(all_angles[IDX].split(' ')[1]) // 10) , int(float(all_angles[IDX].split(' ')[2]) // 10)\n",
    "    pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "    if pos1 == pos2:\n",
    "        count += 1.\n",
    "        idx_0_train.append(IDX)\n",
    "        \n",
    "print \"TRAIN: same angle in {:.3} % of the cases ({})\".format(count / 5999 * 100, len(idx_0_train))\n",
    "\n",
    "sys.stdout.flush()\n",
    "acc = 0.\n",
    "count = 0.\n",
    "for IDX in range(1999):\n",
    "    \n",
    "    pos1, pos2 = int(float(all_angles_test[IDX].split(' ')[1]) // 10) , int(float(all_angles_test[IDX].split(' ')[2]) // 10)\n",
    "    pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "    if np.abs(pos1 - pos2) == 1:\n",
    "        count += 1.\n",
    "        idx_1_test.append(IDX)\n",
    "\n",
    "print \"TEST: adiacent angle in {:.2} % of the cases ({})\".format(count / 1999 * 100, len(idx_1_test))\n",
    "\n",
    "count = 0.\n",
    "for IDX in range(5999):\n",
    "    pos1, pos2 = int(float(all_angles[IDX].split(' ')[1]) // 10) , int(float(all_angles[IDX].split(' ')[2]) // 10)\n",
    "    pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "    if np.abs(pos1 - pos2) == 1:\n",
    "        count += 1.\n",
    "        idx_1_train.append(IDX)\n",
    "        \n",
    "print \"TRAIN: adiacent angle in {:.3} % of the cases ({})\".format(count / 5999 * 100, len(idx_1_train))\n",
    "\n",
    "ang_diff_test = []\n",
    "\n",
    "for IDX in range(1999):\n",
    "    pos1, pos2 = int(float(all_angles_test[IDX].split(' ')[1]) // 10) , int(float(all_angles_test[IDX].split(' ')[2]) // 10)\n",
    "    pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "    ang_diff_test.append(np.abs(pos1 - pos2))\n",
    "    \n",
    "ang_diff_train = []\n",
    "\n",
    "for IDX in range(5999):\n",
    "    pos1, pos2 = int(float(all_angles[IDX].split(' ')[1]) // 10) , int(float(all_angles[IDX].split(' ')[2]) // 10)\n",
    "    pos1, pos2 = correct_pos(pos1), correct_pos(pos2)\n",
    "    ang_diff_train.append(np.abs(pos1 - pos2))\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "_ = ax.hist(ang_diff_train, 16, normed=True)\n",
    "ax.set_title('train')\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "_ = ax.hist(ang_diff_test, 16, normed=True)\n",
    "ax.set_title('test')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and shift correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 390\n",
    "subset = 'test'\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_mix.h5'\n",
    "\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "dataset = h5.get_node(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "channels = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "print ALL_NAMES[subset][IDX]\n",
    "timestamps, addresses = es.loadaerdat(basedir + 'aedat/{}/'.format(subset) + ALL_NAMES[subset][IDX] + '.aedat')\n",
    "timestamps, addresses = remove_trigger(timestamps, addresses)\n",
    "\n",
    "timestamps, channel_id, ear_id, neuron_id, filterbank_id = es.decode_ams1c(timestamps, addresses, return_type=False)\n",
    "\n",
    "# load wav\n",
    "spk1, spk2, _ = re.compile('[0-9]+').split(ALL_NAMES[subset][IDX])\n",
    "_, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "pos1, pos2 = int(float(ALL_ANGLES[subset][IDX].split(' ')[1]) // 10) , int(float(ALL_ANGLES[subset][IDX].split(' ')[2]) // 10)\n",
    "print pos1\n",
    "print pos2\n",
    "fs, w1 = wavfile.read(basedir + 'wavs/{}/'.format(subset) + GTS1[subset][IDX].replace('\\\\', '/') + '.wav')\n",
    "fs, w2 = wavfile.read(basedir + 'wavs/{}/'.format(subset) + GTS2[subset][IDX].replace('\\\\', '/') + '.wav')\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    " \n",
    "ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "m_len = max([len(w1), len(w2)])\n",
    "w1 = np.concatenate([w1, np.zeros(m_len - len(w1),)])\n",
    "w2 = np.concatenate([w2, np.zeros(m_len - len(w2),)])\n",
    "\n",
    "print m_len\n",
    "\n",
    "Y = np.reshape(channels[0].features[IDX], channels[0].feature_shape[IDX])[:, :41]\n",
    "\n",
    "print Y.shape\n",
    "ax.imshow(Y.T, aspect='auto')\n",
    "# ax.plot(np.sum(Y, 1) / 400.0 * 20, 'r')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "\n",
    "K = spike_features(timestamps, channel_id)[2:]\n",
    "\n",
    "env_log = np.sum(Y, 1)\n",
    "env_sps = np.sum(K, 0)\n",
    "\n",
    "k = np.correlate(env_log, env_sps, 'full')\n",
    "\n",
    "shift = np.argmax(np.abs(k)) - len(env_sps)\n",
    "print shift\n",
    "\n",
    "ax.imshow(K[::-1, np.abs(shift):], aspect='auto')\n",
    "# ax.plot(np.sum(K, 0) / 1000.0 * 10 + 20, 'r')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# ax.plot(np.sum(K, 0) / 1000.0 * 25, 'r')\n",
    "# ax.imshow(np.log10(wind_sp(timestamps, channel_id) + 1e-9), aspect='auto')\n",
    "# ax.plot(timestamps, channel_id, 'o')\n",
    "ax.set_xlim([0, Y.shape[0]])\n",
    "# ax.plot()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "ax.set_xlim([0, Y.shape[0]])\n",
    "ax.plot(np.sum(Y, 1) / 400.0 * 20, 'r')\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "ax.plot(np.sum(K, 0) / 1000.0 * 10 + 20, 'r')\n",
    "ax.set_xlim([0, Y.shape[0]])\n",
    "\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 388\n",
    "subset = 'test'\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_mix.h5'\n",
    "\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "dataset = h5.get_node(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "channels = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "print ALL_NAMES[subset][IDX]\n",
    "timestamps, addresses = es.loadaerdat(basedir + 'aedat/{}/'.format(subset) + ALL_NAMES[subset][IDX] + '.aedat')\n",
    "plt.plot(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create dataset with alligned log/spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log = {'train': [], 'test': []}\n",
    "all_spk = {'train': [], 'test': []}\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_mix.h5'\n",
    "\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "\n",
    "channels = h5.list_nodes(os.path.join(os.sep, 'default', 'train'))\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    print \"DOING {}\".format(subset)\n",
    "    channels = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "    \n",
    "    for IDX in tqdm(range(len(ALL_NAMES[subset]))):\n",
    "        timestamps, addresses = es.loadaerdat(basedir + 'aedat/{}/'.format(subset) + ALL_NAMES[subset][IDX] + '.aedat')\n",
    "        timestamps, addresses = remove_trigger(timestamps, addresses)\n",
    "\n",
    "        timestamps, channel_id, ear_id, neuron_id, filterbank_id = es.decode_ams1c(timestamps, addresses, return_type=False)\n",
    "\n",
    "        Y = np.reshape(channels[0].features[IDX], channels[0].feature_shape[IDX])[:, :41]\n",
    "\n",
    "        K = spike_features(timestamps, channel_id)[2:]\n",
    "\n",
    "        env_log = np.sum(Y, 1)\n",
    "        env_sps = np.sum(K, 0)\n",
    "\n",
    "        k = np.correlate(env_log, env_sps, 'full')\n",
    "\n",
    "        shift = np.argmax(np.abs(k)) - len(env_sps)\n",
    "\n",
    "        K = K[:, np.abs(shift):]\n",
    "        K = K[:, :Y.shape[0]]\n",
    "        Y = Y.T\n",
    "\n",
    "        if K.shape[1] != Y.shape[1]:\n",
    "            print K.shape\n",
    "            print Y.shape\n",
    "            raise ValueError()\n",
    "        all_log[subset].append(Y)\n",
    "        all_spk[subset].append(K)\n",
    "\n",
    "\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax[0][0].imshow(all_spk['train'][3], aspect='auto')\n",
    "ax[1][0].imshow(all_log['train'][3], aspect='auto')\n",
    "ax[0][1].imshow(all_spk['test'][3], aspect='auto')\n",
    "ax[1][1].imshow(all_log['test'][3], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump({'log': all_log['train'], 'spk': all_spk['train']}, open('all_log_spk_train_v02.pkl', 'w'))\n",
    "pkl.dump({'log': all_log['test'], 'spk': all_spk['test']}, open('all_log_spk_test_v02.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and train reconstruction model (MLP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_v = ''  # default\n",
    "ds_v = '_v02'\n",
    "print \"TRAIN:\"\n",
    "all_mix_log = pkl.load(open('all_log_spk_train{}.pkl'.format(ds_v), 'r'))['log']\n",
    "print \"\\tMIX LOG => {}\".format(len(all_mix_log))\n",
    "all_mix_spk = pkl.load(open('all_log_spk_train{}.pkl'.format(ds_v), 'r'))['spk']\n",
    "print \"\\tMIX SPK => {}\".format(len(all_mix_spk))\n",
    "print \"TEST:\"\n",
    "all_mix_log_test = pkl.load(open('all_log_spk_test{}.pkl'.format(ds_v), 'r'))['log']\n",
    "print \"\\tMIX LOG => {}\".format(len(all_mix_log_test))\n",
    "all_mix_spk_test = pkl.load(open('all_log_spk_test{}.pkl'.format(ds_v), 'r'))['spk']\n",
    "print \"\\tSPK LOG => {}\".format(len(all_mix_spk_test))\n",
    "\n",
    "# I also use the samples from spk_sep train\n",
    "ds_v = '_v05'\n",
    "print \"TRAIN:\"\n",
    "all_sep_log = pkl.load(open('all_sep_spk_train{}.pkl'.format(ds_v), 'r'))['log']\n",
    "print \"\\tSEP LOG => {}\".format(len(all_sep_log))\n",
    "all_sep_spk = pkl.load(open('all_sep_spk_train{}.pkl'.format(ds_v), 'r'))['spk']\n",
    "print \"\\tSEP SPK => {}\".format(len(all_sep_spk))\n",
    "print \"TEST:\"\n",
    "all_sep_log_test = pkl.load(open('all_sep_spk_test{}.pkl'.format(ds_v), 'r'))['log']\n",
    "print \"\\tSEP LOG => {}\".format(len(all_sep_log_test))\n",
    "all_sep_spk_test = pkl.load(open('all_sep_spk_test{}.pkl'.format(ds_v), 'r'))['spk']\n",
    "print \"\\tSEP SPK => {}\".format(len(all_sep_spk_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for IDX in tqdm(range(20)):\n",
    "    f, ax = plt.subplots(2, 2, figsize=(20,10))\n",
    "\n",
    "    im = ax[0][0].imshow(all_sep_spk[IDX], aspect='auto')\n",
    "    plt.colorbar(im, ax=ax[0][0])\n",
    "    im = ax[1][0].imshow(all_sep_log[IDX], aspect='auto')\n",
    "    plt.colorbar(im, ax=ax[1][0])\n",
    "    im = ax[0][1].imshow(all_sep_spk_test[IDX], aspect='auto')\n",
    "    plt.colorbar(im, ax=ax[0][1])\n",
    "    im = ax[1][1].imshow(all_sep_log_test[IDX], aspect='auto')\n",
    "    plt.colorbar(im, ax=ax[1][1])\n",
    "\n",
    "    plt.savefig('./imgs/train/{}_v05.png'.format(IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train I use the all mix plus the separated train\n",
    "# all_x_train = all_mix_spk + all_mix_spk_test + all_sep_spk\n",
    "# all_y_train = all_mix_log + all_mix_log_test + all_sep_log\n",
    "# or only the separated one\n",
    "all_x_train = all_sep_spk\n",
    "all_y_train = all_sep_log\n",
    "# or only the mixed one\n",
    "# all_x_train = all_mix_spk\n",
    "# all_y_train = all_mix_log\n",
    "\n",
    "all_x_test = all_sep_spk_test\n",
    "all_y_test = all_sep_log_test\n",
    "\n",
    "Y_train_pre = np.concatenate(all_y_train, 1)\n",
    "print Y_train_pre.shape\n",
    "X_train_pre = np.concatenate(all_x_train, 1)\n",
    "print X_train_pre.shape\n",
    "\n",
    "Y_test_pre = np.concatenate(all_y_test, 1)\n",
    "print Y_test_pre.shape\n",
    "X_test_pre = np.concatenate(all_x_test, 1)\n",
    "print X_test_pre.shape\n",
    "\n",
    "## LTD\n",
    "# Y_train_pre = Y_train_pre[:20]\n",
    "# Y_test_pre = Y_test_pre[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = 10\n",
    "shift = 1\n",
    "X_train, Y_train = get_ctx_win(X_train_pre, Y_train_pre, ctx=ctx, shift=shift)\n",
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "\n",
    "X_test, Y_test = get_ctx_win(X_test_pre, Y_test_pre, ctx=ctx, shift=shift)\n",
    "print X_test.shape \n",
    "print Y_test.shape\n",
    "\n",
    "# try to normalize\n",
    "mean_x = np.mean(X_train, 0)\n",
    "std_x = np.std(X_train, 0)\n",
    "mean_y = np.mean(Y_train, 0)\n",
    "std_y = np.std(Y_train, 0)\n",
    "\n",
    "# X_train = np.log10(X_train + 1e-9)\n",
    "# X_test = np.log10(X_test + 1e-9)\n",
    "\n",
    "# Y_train = np.log10(Y_train + 1e-9)\n",
    "# Y_test = np.log10(Y_test + 1e-9)\n",
    "\n",
    "# visually, train vs test\n",
    "f, ax = plt.subplots(2, 2, figsize=(20,10))\n",
    "\n",
    "beg = 5200\n",
    "end = 5300\n",
    "\n",
    "ax[0][0].imshow(X_test.T[:, beg:end], aspect='auto')\n",
    "ax[1][0].imshow(Y_test.T[:, beg:end], aspect='auto')\n",
    "\n",
    "ax[0][1].imshow(X_train.T[:, beg:end], aspect='auto')\n",
    "ax[1][1].imshow(Y_train.T[:, beg:end], aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(1024, input_shape=(X_train.shape[1],)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(Y_train.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "mc = keras.callbacks.ModelCheckpoint('./spk2log_mix_v05.h5', monitor='val_loss', save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=True, batch_size=256, callbacks=[estop, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "plt.plot(results.history['loss'], label='Train loss')\n",
    "plt.plot(results.history['val_loss'], label='Test loss')\n",
    "plt.legend()\n",
    "model = load_model('spk2log_mix_v05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually, train vs test\n",
    "f, ax = plt.subplots(2, 2, figsize=(20,10))\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "\n",
    "beg = 5200\n",
    "end = 5300\n",
    "\n",
    "ax[0][0].imshow(Y_test.T[:, beg:end], aspect='auto')\n",
    "ax[1][0].imshow(Y_pred_test.T[:, beg:end], aspect='auto')\n",
    "\n",
    "ax[0][1].imshow(Y_train.T[:, beg:end], aspect='auto')\n",
    "ax[1][1].imshow(Y_pred_train.T[:, beg:end], aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Regression v2 (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = 30\n",
    "X_train_lstm, Y_train_lstm = get_ctx_win2(X_train_pre, Y_train_pre, ctx=TS)\n",
    "X_test_lstm, Y_test_lstm = get_ctx_win2(X_test_pre, Y_test_pre, ctx=TS)\n",
    "\n",
    "print X_train_lstm.shape\n",
    "print Y_train_lstm.shape\n",
    "print X_test_lstm.shape\n",
    "print Y_test_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "model2.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model2.add(TimeDistributed(Dense(Y_train_lstm.shape[2])))\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "mc = keras.callbacks.ModelCheckpoint('./spk2log_mix_v03_lstm.h5', monitor='val_loss', save_best_only=True)\n",
    "results = model2.fit(X_train_lstm, Y_train_lstm, validation_data=(X_test_lstm, Y_test_lstm), epochs=100, verbose=True, batch_size=256, callbacks=[estop, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually, train vs test\n",
    "f, ax = plt.subplots(2, 2, figsize=(20,10))\n",
    "Y_pred_train_lstm = model2.predict(X_train_lstm)\n",
    "Y_pred_test_lstm = model2.predict(X_test_lstm)\n",
    "\n",
    "beg = 5200\n",
    "end = 5300\n",
    "\n",
    "ax[0][0].imshow(Y_test_lstm[13].T, aspect='auto')\n",
    "ax[1][0].imshow(Y_pred_test_lstm[13].T, aspect='auto')\n",
    "\n",
    "ax[0][1].imshow(Y_train_lstm[13].T, aspect='auto')\n",
    "ax[1][1].imshow(Y_pred_train_lstm[13].T, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = MLPRegressor(hidden_layer_sizes=(256, 256), verbose=True, early_stopping=True)\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump(lr, open('mlp_256_256_spk2log.pkl', 'wb'))\n",
    "lr = pkl.load(open('mlp_256_256_spk2log.pkl', 'r')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = lr.predict(X_train)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "ax.imshow(Y_train.T[:, 1000:1200], aspect='auto')\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "ax.imshow(Y_pred_train.T[:, 1000:1200], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = lr.predict(X_test)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "ax.imshow(Y_test.T[:, 1000:1200], aspect='auto')\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "ax.imshow(Y_pred.T[:, 1000:1200], aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sample \n",
    "regressor = model # lr\n",
    "IDX = 1001\n",
    "\n",
    "ex_x = all_sep_spk_test[IDX]\n",
    "ex_y = all_sep_log_test[IDX]\n",
    "print ex_x.shape \n",
    "print ex_y.shape\n",
    "\n",
    "ex_x, ex_y = get_ctx_win(ex_x, ex_y, ctx=3, shift=1)\n",
    "print ex_x.shape \n",
    "print ex_y.shape\n",
    "\n",
    "ex_pred = regressor.predict(ex_x)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(3,1,1)\n",
    "ax.imshow(ex_y.T, aspect='auto')\n",
    "ax = fig.add_subplot(3,1,2)\n",
    "ax.imshow(ex_pred.T, aspect='auto')\n",
    "ax = fig.add_subplot(3,1,3)\n",
    "d1 = np.diff(ex_pred, axis=1)\n",
    "d2 = np.diff(d1, axis=1)\n",
    "deltas = np.concatenate([ex_pred[:, 2:], d1[:, 1:], d2], axis=1)\n",
    "ax.imshow(deltas.T, aspect='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sample \n",
    "regressor = model # lr\n",
    "ctx = 3\n",
    "shift = 1\n",
    "ds_v = '_v02'\n",
    "all_y = {'train': [], 'test': []}\n",
    "all_lbl = {'train': pkl.load(open('all_sep_spk_train{}.pkl'.format(ds_v), 'r'))['lbl'], 'test': pkl.load(open('all_sep_spk_test{}.pkl'.format(ds_v), 'r'))['lbl']} \n",
    "\n",
    "for task, x, y in zip(['train', 'test'], [all_sep_spk, all_sep_spk_test], [all_sep_log, all_sep_log_test]): \n",
    "    for ex_x, ex_y in tqdm(zip(x, y)):\n",
    "        ex_x, ex_y = get_ctx_win(ex_x, ex_y, ctx=ctx, shift=shift)\n",
    "\n",
    "        ex_pred = regressor.predict(ex_x)\n",
    "        all_y[task].append(ex_pred.T)\n",
    "\n",
    "print len(all_y['train'])\n",
    "print len(all_lbl['train'])\n",
    "print len(all_y['test'])\n",
    "print len(all_lbl['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check\n",
    "IDX = 1002\n",
    "f, ax = plt.subplots(2,2)\n",
    "ax[0][0].imshow(all_y['train'][IDX], aspect='auto')\n",
    "ax[1][0].imshow(all_sep_log[IDX], aspect='auto')\n",
    "ax[0][1].imshow(all_y['test'][IDX], aspect='auto')\n",
    "ax[1][1].imshow(all_sep_log_test[IDX], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it\n",
    "ds_v = '_v02'\n",
    "pkl.dump({'spk': all_y['train'], 'lbl': all_lbl['train']}, open('all_log_prj_train{}.pkl'.format(ds_v), 'w'))\n",
    "pkl.dump({'spk': all_y['test'], 'lbl': all_lbl['test']}, open('all_log_prj_test{}.pkl'.format(ds_v), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check what kind of error distribution there is in reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = model\n",
    "\n",
    "# Y_pred = regressor.predict(X_test)\n",
    "Q_test = (Y_pred_test - Y_test).reshape(-1)\n",
    "\n",
    "# Y_pred_train = regressor.predict(X_train)\n",
    "Q_train = (Y_pred_train - Y_train).reshape(-1)\n",
    "\n",
    "print Q_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2)\n",
    "# test error distribution\n",
    "\n",
    "a = ax[0].hist(Q_train, 100, normed=True)\n",
    "xt = a[1]  \n",
    "xmin, xmax = min(xt), max(xt)  \n",
    "lnspc = np.linspace(xmin, xmax, len(Q_train))\n",
    "\n",
    "# gaussian\n",
    "an, bn = stats.norm.fit(Q_train)  \n",
    "pdf_norm = stats.norm.pdf(lnspc, an, bn)  \n",
    "ax[0].plot(lnspc, pdf_norm, label=\"Gaussian\")\n",
    "\n",
    "# laplace\n",
    "al, bl = stats.laplace.fit(Q_train)  \n",
    "pdf_laplace = stats.laplace.pdf(lnspc, al, bl)  \n",
    "ax[0].plot(lnspc, pdf_laplace, label=\"Laplace\")\n",
    "\n",
    "# gamma\n",
    "ag, bg, cg = stats.gamma.fit(Q_train)  \n",
    "pdf_gamma = stats.gamma.pdf(lnspc, ag, bg, cg)  \n",
    "ax[0].plot(lnspc, pdf_gamma, label=\"Gamma\")\n",
    "\n",
    "ax[0].legend()\n",
    "\n",
    "a = ax[1].hist(Q_test, 100, normed=True)\n",
    "xt = a[1]  \n",
    "xmin, xmax = min(xt), max(xt)  \n",
    "lnspc = np.linspace(xmin, xmax, len(Q_test))\n",
    "\n",
    "# gaussian\n",
    "an, bn = stats.norm.fit(Q_test)  \n",
    "pdf_norm = stats.norm.pdf(lnspc, an, bn)  \n",
    "ax[1].plot(lnspc, pdf_norm, label=\"Gaussian\")\n",
    "\n",
    "# laplace\n",
    "al, bl = stats.laplace.fit(Q_test)  \n",
    "pdf_laplace = stats.laplace.pdf(lnspc, al, bl)  \n",
    "ax[1].plot(lnspc, pdf_laplace, label=\"Laplace\")\n",
    "\n",
    "# laplace\n",
    "ag, bg, cg = stats.gamma.fit(Q_test)  \n",
    "pdf_gamma = stats.gamma.pdf(lnspc, ag, bg, cg)  \n",
    "ax[1].plot(lnspc, pdf_gamma, label=\"Gamma\")\n",
    "\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = stats.norm.fit(Q_test)  \n",
    "pdf_norm = stats.norm.pdf(lnspc, mu, sigma)  \n",
    "plt.plot(lnspc, pdf_norm, label=\"Gaussian\")\n",
    "\n",
    "y = np.random.normal(size=100000) * sigma + mu\n",
    "_ = plt.hist(y, 100, normed=True, label='numpy', alpha=0.5)\n",
    "\n",
    "print mu\n",
    "print sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot normed histogram\n",
    "plt.hist(Q.reshape(-1), 100, normed=True)\n",
    "\n",
    "# find minimum and maximum of xticks, so we know\n",
    "# where we should compute theoretical distribution\n",
    "xt = plt.xticks()[0]  \n",
    "xmin, xmax = min(xt), max(xt)  \n",
    "lnspc = np.linspace(xmin, xmax, len(Q.reshape(-1)))\n",
    "# exactly same as above\n",
    "ag,bg = stats.laplace.fit(Q.reshape(-1))  \n",
    "pdf_laplace = stats.laplace.pdf(lnspc, ag, bg)  \n",
    "plt.plot(lnspc, pdf_laplace, label=\"Laplace\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single separation and reconstrucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 100\n",
    "subset = 'train'\n",
    "ctx = 5\n",
    "shift = 1\n",
    "\n",
    "T, C, w1, w2, fs, _, amax = sps(IDX, subset, sigma=5)\n",
    "\n",
    "spkf1 = spike_features(T[0], C[0])[2:]\n",
    "spkf2 = spike_features(T[1], C[1])[2:]\n",
    "\n",
    "ex_x = spkf1[::-1]\n",
    "ex_y = w1\n",
    "\n",
    "n_win = (ex_x.shape[1] - ctx * 2) // shift\n",
    "\n",
    "ex_x = np.array([ex_x[:, i - ctx:i + ctx + 1].reshape(-1,) for i in range(ctx, n_win * shift, shift)])\n",
    "print ex_x.shape \n",
    "ex_y = ex_y[:, ctx + 1:-(ctx * 2 - 1)].T\n",
    "print ex_y.shape\n",
    "\n",
    "\n",
    "ex_pred = lr.predict(ex_x)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "ax.imshow(ex_y.T, aspect='auto')\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "ax.imshow(ex_pred.T, aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(VALID_IDX['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process SPS and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.disable()\n",
    "from twilio.rest import Client\n",
    "client = Client(\"ACa5636b5b88891fc0789fe740f6d94d8a\", \"2194cba7f961a8b9cdd687040c050514\")\n",
    "FROM = \"+18482510673\"\n",
    "TO = \"+16094015565\"\n",
    "# print '',\n",
    "# sys.stdout.flush()\n",
    "all_sep_spk = {'train': [], 'test': []}\n",
    "all_sep_log = {'train': [], 'test': []}\n",
    "all_label = {'train': [], 'test': []}\n",
    "\n",
    "ds_v = '_v07'\n",
    "valid_idx_07 = []\n",
    "ALL_T = []\n",
    "ALL_C = []\n",
    "\n",
    "# h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_sep.h5'\n",
    "\n",
    "# h5 = tables.open_file(h5file, 'r')\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    \n",
    "#     channels = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "    \n",
    "#     for IDX in tqdm(range(len(ALL_NAMES[subset]))):\n",
    "#         if IDX in VALID_IDX[subset]:\n",
    "    for IDX in tqdm(VALID_IDX[subset]):\n",
    "        \n",
    "        T, C = sps_fast(IDX, subset, sigma=3, adj=1)\n",
    "        \n",
    "        _, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "        all_label[subset].append(utt1)\n",
    "        all_label[subset].append(utt2)\n",
    "        if IDX % 500 == 0:\n",
    "            client.messages.create(to=TO, from_=FROM, body=\"SPS: Doing {} of subset {}\".format(IDX, subset))\n",
    "\n",
    "        for i in range(2):\n",
    "            \n",
    "            if len(T) > 0 and len(T[i]) > 10:\n",
    "                ALL_T.append(T[i])\n",
    "                ALL_C.append(C[i])\n",
    "                K = spike_count_features_by_time(np.array(T[i]), np.array(C[i]).astype('int32')).T\n",
    "    #                 K = spike_features(T[i], C[i], limit=False)[2:]\n",
    "    #                 Y = np.reshape(channels[0].features[idx], channels[0].feature_shape[idx])[:, :41].T\n",
    "\n",
    "    #                 env_log = np.sum(Y, 0)\n",
    "    #                 env_sps = np.sum(K, 0)\n",
    "\n",
    "    #                 k = np.correlate(env_log, env_sps, 'full')\n",
    "    #                 shift = np.argmax(np.abs(k)) - len(env_log)\n",
    "\n",
    "    #                 K = K[:, np.abs(shift):]\n",
    "    #                 K = K[:, :Y.shape[1]]\n",
    "                all_sep_spk[subset].append(K)\n",
    "    #                 all_sep_log[subset].append(Y)\n",
    "                valid_idx_07.append(IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.disable()\n",
    "import sys\n",
    "sys.stdout.flush()\n",
    "from twilio.rest import Client\n",
    "client = Client(\"ACa5636b5b88891fc0789fe740f6d94d8a\", \"2194cba7f961a8b9cdd687040c050514\")\n",
    "FROM = \"+18482510673\"\n",
    "TO = \"+16094015565\"\n",
    "# print '',\n",
    "# sys.stdout.flush()\n",
    "all_sep_spk = {'train': [], 'test': []}\n",
    "all_sep_log = {'train': [], 'test': []}\n",
    "all_label = {'train': [], 'test': []}\n",
    "\n",
    "ds_v = '_v07'\n",
    "\n",
    "ALL_T = {'train': [], 'test': []}\n",
    "ALL_C = {'train': [], 'test': []}\n",
    "\n",
    "# h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_sep.h5'\n",
    "\n",
    "# h5 = tables.open_file(h5file, 'r')\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    for IDX in tqdm(range(len(ALL_NAMES[subset]))):\n",
    "        \n",
    "        T, C, _, _, _, _, _, _, _, _ = sps(IDX, subset, sigma=3, fast=True)\n",
    "        \n",
    "        _, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "        all_label[subset].append(utt1)\n",
    "        all_label[subset].append(utt2)\n",
    "        if IDX % 500 == 0 and IDX != 0:\n",
    "            client.messages.create(to=TO, from_=FROM, body=\"SPS: Doing {} of subset {}\".format(IDX, subset))\n",
    "        for i in range(2):\n",
    "            ALL_T[subset].append(T[i])\n",
    "            ALL_C[subset].append(C[i])\n",
    "            \n",
    "            K = wind_sp(T[i], C[i], limit=True)[::-1]\n",
    "            all_sep_spk[subset].append(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.disable()\n",
    "import sys\n",
    "sys.stdout.flush()\n",
    "from twilio.rest import Client\n",
    "client = Client(\"ACa5636b5b88891fc0789fe740f6d94d8a\", \"2194cba7f961a8b9cdd687040c050514\")\n",
    "FROM = \"+18482510673\"\n",
    "TO = \"+16094015565\"\n",
    "# print '',\n",
    "# sys.stdout.flush()\n",
    "all_sep_spk_new = {'train': [], 'test': []}\n",
    "\n",
    "ds_v = '_v07'\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    for IDX in tqdm(range(len(ALL_NAMES[subset]))):\n",
    "        for i in [IDX * 2, IDX * 2 + 1]:\n",
    "            t = ALL_T[subset][i]\n",
    "            c = ALL_C[subset][i]\n",
    "            if len(t) > 0:\n",
    "                K = wind_sp2(t, c)[::-1]\n",
    "                if K.shape[1] > 12:\n",
    "                    K = simple_low_pass(K.T).T\n",
    "                    K /= (np.std(K, 1, keepdims=True) + 1e-8)\n",
    "                    if not np.isnan(np.mean(K)):\n",
    "                        all_sep_spk_new[subset].append(K)\n",
    "                    else:\n",
    "                        print \"{} / {}\".format(subset, IDX)\n",
    "                        all_sep_spk_new[subset].append(np.random.rand(64, 50))\n",
    "                else:\n",
    "                    print \"{} / {}\".format(subset, IDX)\n",
    "                    all_sep_spk_new[subset].append(np.random.rand(64, 50))\n",
    "            else:\n",
    "                print \"{} / {}\".format(subset, IDX)\n",
    "                all_sep_spk_new[subset].append(np.random.rand(64, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ds_v\n",
    "print len(ALL_T['train'])\n",
    "print len(ALL_C['train'])\n",
    "print len(all_label['train'])\n",
    "print len(all_label['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(all_sep_spk_new['test'])\n",
    "print len(all_sep_spk_new['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump({'T': ALL_T['train']}, open('all_T_v7_train.pkl', 'w'))\n",
    "pkl.dump({'C': ALL_C['train']}, open('all_C_v7_train.pkl', 'w'))\n",
    "pkl.dump({'T': ALL_T['test']}, open('all_T_v7_test.pkl', 'w'))\n",
    "pkl.dump({'C': ALL_C['test']}, open('all_C_v7_test.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump({'spk': all_sep_spk_new['train'], 'lbl': all_label['train']}, open('all_sep_spk_train_777_{}.pkl'.format(ds_v), 'w'))\n",
    "pkl.dump({'spk': all_sep_spk_new['test'], 'lbl': all_label['test']}, open('all_sep_spk_test_777_{}.pkl'.format(ds_v), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 1e30\n",
    "max_ = 0\n",
    "for subset in ['train', 'test']:\n",
    "    for i in range(len(all_sep_spk_new[subset])):\n",
    "        A = all_sep_spk_new[subset][i]\n",
    "        A /= np.max(A)\n",
    "        all_sep_spk_new[subset][i] = A\n",
    "        max_ = max(max_, np.max(A))\n",
    "        min_ = min(min_, np.min(A))\n",
    "        if np.isnan(np.mean(A)) or np.mean(A) == 0:\n",
    "            print \"{} / {} / {}\".format(subset, i, np.mean(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "\tSEP SPK => 12000\n",
      "TEST:\n",
      "\tSEP SPK => 4000\n"
     ]
    }
   ],
   "source": [
    "ds_v = '_v07'\n",
    "print \"TRAIN:\"\n",
    "all_sep_spk = pkl.load(open('all_sep_spk_train_777_{}.pkl'.format(ds_v), 'r'))['spk']\n",
    "print \"\\tSEP SPK => {}\".format(len(all_sep_spk))\n",
    "print \"TEST:\"\n",
    "all_sep_spk_test = pkl.load(open('all_sep_spk_test_777_{}.pkl'.format(ds_v), 'r'))['spk']\n",
    "print \"\\tSEP SPK => {}\".format(len(all_sep_spk_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump({'log': all_sep_log, 'spk': all_sep_spk, 'lbl': all_label['train']}, open('all_sep_spk_train{}.pkl'.format(ds_v), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 58)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d7545b4a4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plasma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ax[1][0].imshow(all_sep_log[subset][IDX * 2], aspect='auto')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_label' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d35a00a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset = 'train'\n",
    "IDX = 325\n",
    "f, ax = plt.subplots(2, 1, figsize=(10,10))\n",
    "\n",
    "B = all_sep_spk[IDX * 2 + 1]\n",
    "A = all_sep_spk[IDX * 2]\n",
    "print(A.shape)\n",
    "im1 = ax[0].imshow(A , aspect='auto',cmap=plt.get_cmap('plasma'))\n",
    "ax[0].set_title(all_label[subset][IDX * 2])\n",
    "plt.colorbar(im1, ax=ax[0])\n",
    "# ax[1][0].imshow(all_sep_log[subset][IDX * 2], aspect='auto')\n",
    "im2 = ax[1].imshow(B, aspect='auto',cmap=plt.get_cmap('plasma'))\n",
    "ax[1].set_title(all_label[subset][IDX * 2 + 1])\n",
    "# ax[1][1].imshow(all_sep_log[subset][IDX * 2 + 1], aspect='auto')\n",
    "plt.colorbar(im2, ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'train'\n",
    "IDX = 3\n",
    "f, ax = plt.subplots(2, 1, figsize=(10,10))\n",
    "\n",
    "B = simple_low_pass(all_sep_spk_new[subset][IDX * 2 + 1].T).T\n",
    "A = simple_low_pass(all_sep_spk_new[subset][IDX * 2].T).T\n",
    "print(A.shape)\n",
    "im1 = ax[0].imshow(A / (np.std(A, 1, keepdims=True) + 1e-8), aspect='auto',cmap=plt.get_cmap('plasma'))\n",
    "ax[0].set_title(all_label[subset][IDX * 2])\n",
    "plt.colorbar(im1, ax=ax[0])\n",
    "# ax[1][0].imshow(all_sep_log[subset][IDX * 2], aspect='auto')\n",
    "im2 = ax[1].imshow(B / (np.std(B, 1, keepdims=True) + 1e-8), aspect='auto',cmap=plt.get_cmap('plasma'))\n",
    "ax[1].set_title(all_label[subset][IDX * 2 + 1])\n",
    "# ax[1][1].imshow(all_sep_log[subset][IDX * 2 + 1], aspect='auto')\n",
    "plt.colorbar(im2, ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer = []\n",
    "IDX = VALID_IDX['train'][55]\n",
    "subset = 'train'\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_sep.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "log_sep = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_mix.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "log_mix = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_spk_mix.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "spk_mix = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "f, ax = plt.subplots(2, 3, figsize=(20,10))\n",
    "T, C, w1, w2, fs, _, pos = sps(IDX, subset, sigma=3)\n",
    "_, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "        \n",
    "ax[0][2].imshow(np.reshape(spk_mix[0].features[IDX], spk_mix[0].feature_shape[IDX]).T, aspect='auto')\n",
    "ax[1][2].imshow(np.reshape(log_mix[0].features[IDX], log_mix[0].feature_shape[IDX])[:, :41].T, aspect='auto')\n",
    "\n",
    "for i, utt, idx, p in zip([0, 1], [utt1, utt2], [IDX * 2, IDX * 2 + 1], pos):\n",
    "    K = spike_features(T[i], C[i])[2:]\n",
    "    Y = np.reshape(log_sep[0].features[idx], log_sep[0].feature_shape[idx])[:, :41].T\n",
    "    env_log = np.sum(Y, 0)\n",
    "    env_sps = np.sum(K, 0)\n",
    "    k = np.correlate(env_log, env_sps, 'full')\n",
    "    shift = np.argmax(np.abs(k)) - len(env_sps)\n",
    "    K = K[:, np.abs(shift):]\n",
    "    K = K[:, :Y.shape[1]]\n",
    "    ax[0][i].imshow(K, aspect='auto')\n",
    "    ax[0][i].set_title(utt + \" - \" + str(p * 10))\n",
    "    ax[1][i].imshow(Y, aspect='auto')\n",
    "    fixer.append(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sep_spk = {'train': []}\n",
    "all_sep_log = {'train': []}\n",
    "all_label = {'train': []}\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_spk_sep.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "spk = h5.list_nodes(os.path.join(os.sep, 'default', 'train'))\n",
    "\n",
    "h5file2 = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_sep.h5'\n",
    "h52 = tables.open_file(h5file2, 'r')\n",
    "log = h52.list_nodes(os.path.join(os.sep, 'default', 'train'))\n",
    "\n",
    "for idx in range(len(ALL_NAMES['train'])):\n",
    "    _, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES['train'][idx])\n",
    "    all_label['train'].append(utt1)\n",
    "    all_label['train'].append(utt2)\n",
    "\n",
    "for idx in range(len(log[0].features)):\n",
    "\n",
    "    Y = np.reshape(spk[0].features[idx], spk[0].feature_shape[idx]).T\n",
    "    all_sep_spk['train'].append(Y)\n",
    "    \n",
    "    Y = np.reshape(log[0].features[idx], log[0].feature_shape[idx])[:, :41].T\n",
    "    all_sep_log['train'].append(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(all_sep_spk['train'])\n",
    "print len(all_sep_log['train'])\n",
    "print len(all_label['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump({'log': all_sep_log['train'], 'spk': all_sep_spk['train'], 'lbl': all_label['train']}, open('all_sep_spk_train.pkl', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = pkl.load(open('all_sep_spk_test.pkl', 'r'))\n",
    "\n",
    "d_test['spk'][388 * 2] = fixer[0]\n",
    "d_test['spk'][388 * 2 + 1] = fixer[1]\n",
    "\n",
    "all_sep_spk = {'test': d_test['spk']}\n",
    "all_sep_log = {'test': d_test['log']}\n",
    "all_label = {'test': d_test['lbl']}\n",
    "pkl.dump({'log': all_sep_log['test'], 'spk': all_sep_spk['test'], 'lbl': all_label['test']}, open('all_sep_spk_test.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VERBOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer = []\n",
    "IDX = 10\n",
    "subset = 'train'\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_sep.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "log_sep = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_mix.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "log_mix = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_spk_mix.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "spk_mix = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "f, ax = plt.subplots(3, 3, figsize=(20,10))\n",
    "T, C, w1, w2, fs, amax, pos, t, c, e = sps(IDX, subset, sigma=3, verbose=True)\n",
    "_, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "        \n",
    "ax[0][2].imshow(np.reshape(spk_mix[0].features[IDX + 1], spk_mix[0].feature_shape[IDX + 1]).T, aspect='auto', cmap=plt.get_cmap('inferno'))\n",
    "ax[1][2].imshow(np.reshape(log_mix[0].features[IDX + 1], log_mix[0].feature_shape[IDX + 1])[:, :41].T, aspect='auto', cmap=plt.get_cmap('inferno'))\n",
    "\n",
    "for i, utt, idx, p in zip([0, 1], [utt1, utt2], [IDX * 2, IDX * 2 + 1], pos):\n",
    "    K = spike_features(np.array(T[i]), np.array(C[i]).astype('int32'))\n",
    "    Y = np.reshape(log_sep[0].features[idx + 1], log_sep[0].feature_shape[idx + 1])[:, :41].T\n",
    "    env_log = np.sum(Y, 0)\n",
    "    env_sps = np.sum(K, 0)\n",
    "    \n",
    "    env_log2 = np.hstack([env_log, np.zeros((len(env_sps) - len(env_log),))])\n",
    "    d1 = np.correlate(env_log2 - np.mean(env_log2), env_sps - np.mean(env_sps), 'full') \n",
    "    shift = np.argmax(np.abs(d1)) - len(env_sps)\n",
    "    \n",
    "    K = K[:, np.abs(shift):]\n",
    "    K = K[:, :Y.shape[1]]\n",
    "    ax[2][i].plot(T[i], C[i], 'o')\n",
    "    ax[0][i].imshow(K[::-1], aspect='auto')\n",
    "    ax[0][i].set_title(utt + \" - \" + str(p * 10))\n",
    "    ax[1][i].imshow(Y, aspect='auto')\n",
    "    fixer.append(K)\n",
    "\n",
    "a = ax[2][2].hist(amax, bins=range(19), normed=True, label='amax', alpha=0.5)\n",
    "ax[2][2].plot([pos[0] + 0.5, pos[0] + 0.5], [0, a[0][pos[0]]], label='pos0', linewidth=5)\n",
    "ax[2][2].plot([pos[1] + 0.5, pos[1] + 0.5], [0, a[0][pos[1]]], label='pos1', linewidth=5)\n",
    "_ = ax[2][2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(env_log)\n",
    "# plt.figure()\n",
    "# plt.plot(env_sps[:80])\n",
    "env_log2 = np.hstack([env_log, np.zeros((len(env_sps) - len(env_log),))])\n",
    "\n",
    "d1 = np.correlate(env_log2 - np.mean(env_log2), env_sps - np.mean(env_sps), 'full') \n",
    "plt.plot(d1)\n",
    "shift = np.argmax(np.abs(d1)) - len(env_sps)\n",
    "print shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer = []\n",
    "IDX = 6\n",
    "subset = 'train'\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_sep.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "log_sep = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_log_mix.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "log_mix = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "h5file = '/Data/DATASETS/CAESAR_TIDIGITS/tidigits_spk_mix.h5'\n",
    "h5 = tables.open_file(h5file, 'r')\n",
    "spk_mix = h5.list_nodes(os.path.join(os.sep, 'default', subset))\n",
    "\n",
    "f, ax = plt.subplots(3, 3, figsize=(20,10))\n",
    "T, C, w1, w2, fs, amax, pos = sps(IDX, subset, sigma=3, adj=1, prior='', verbose=True)\n",
    "_, utt1, utt2 = re.compile('[A-Z]+').split(ALL_NAMES[subset][IDX])\n",
    "        \n",
    "ax[0][2].imshow(np.reshape(spk_mix[0].features[IDX], spk_mix[0].feature_shape[IDX]).T, aspect='auto', cmap=plt.get_cmap('inferno'))\n",
    "ax[1][2].imshow(np.reshape(log_mix[0].features[IDX], log_mix[0].feature_shape[IDX])[:, :41].T, aspect='auto', cmap=plt.get_cmap('inferno'))\n",
    "\n",
    "for i, utt, idx, p in zip([0, 1], [utt1, utt2], [IDX * 2, IDX * 2 + 1], pos):\n",
    "    K = spike_count_features_by_time(np.array(T[i]), np.array(C[i]).astype('int32')).T\n",
    "    Y = np.reshape(log_sep[0].features[idx], log_sep[0].feature_shape[idx])[:, :41].T\n",
    "    env_log = np.sum(Y, 0)\n",
    "    env_sps = np.sum(K, 0)\n",
    "    k = np.correlate(env_log, env_sps, 'full')\n",
    "    shift = np.argmax(np.abs(k)) - len(env_log)\n",
    "#     plt.figure()\n",
    "#     plt.plot(env_log)\n",
    "#     plt.plot(env_sps)\n",
    "    print shift\n",
    "#     K = K[:, np.abs(shift):]\n",
    "#     K = K[:, :Y.shape[1]]\n",
    "    ax[2][i].plot(T[i], C[i], 'o')\n",
    "    ax[0][i].imshow(K[::-1], aspect='auto')\n",
    "    ax[0][i].set_title(utt + \" - \" + str(p * 10))\n",
    "    ax[1][i].imshow(Y, aspect='auto')\n",
    "    fixer.append(K)\n",
    "\n",
    "a = ax[2][2].hist(amax, bins=range(19), normed=True, label='amax', alpha=0.5)\n",
    "ax[2][2].plot([pos[0] + 0.5, pos[0] + 0.5], [0, a[0][pos[0]]], label='pos0', linewidth=5)\n",
    "ax[2][2].plot([pos[1] + 0.5, pos[1] + 0.5], [0, a[0][pos[1]]], label='pos1', linewidth=5)\n",
    "_ = ax[2][2].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = spike_features(T[0], C[0], limit=True)[2:]\n",
    "Y = np.reshape(log_sep[0].features[idx], log_sep[0].feature_shape[idx])[:, :41].T\n",
    "env_log = np.sum(Y, 0)\n",
    "env_sps = np.sum(K, 0)\n",
    "k = np.correlate(env_log, env_sps, 'full')\n",
    "shift = np.argmax(np.abs(k)) - len(env_log)\n",
    "print shift\n",
    "plt.figure()\n",
    "plt.plot(env_log)\n",
    "plt.figure()\n",
    "plt.plot(env_sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_sp2(ts, ch, w=0.001, limit=False, noise=False):\n",
    "    ts_int = (ts // w).astype('int32')\n",
    "    if len(ts_int) < 1:\n",
    "        ts_int = np.array([0,0])\n",
    "\n",
    "    A = np.zeros((np.max(ts_int) + 3000, 64))\n",
    "    if noise:\n",
    "        A += np.abs(np.random.randn(A.shape[0], A.shape[1]))\n",
    "\n",
    "    for _t, _c in zip(ts_int, ch):\n",
    "        A[_t, _c] += 1\n",
    "        \n",
    "    if limit:\n",
    "        A = np.minimum(A, np.ones_like(A))\n",
    "    # returning [ch, T]\n",
    "    return A.T\n",
    "\n",
    "f, ax = plt.subplots(2,1, figsize=(10,10))\n",
    "ax[0].plot(T[0], C[0], 'o')\n",
    "A = spike_features(T[1], C[1])\n",
    "# A = wind_sp(np.array(T[1]), np.array(C[1]).astype('int32'), limit=True, noise=False)\n",
    "# A = exp_feat(A, win=0.05, l=30, tpe='lap')\n",
    "# A = np.log10(A + 1e-9)\n",
    "# A = simple_low_pass(A.T).T\n",
    "print A.shape\n",
    "ax[1].imshow(A, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPK ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_streams(streams, max_len, bias=0, fill=-1.0):\n",
    "    returned_streams = []\n",
    "    for stream in streams:\n",
    "        num_items = len(stream)\n",
    "        # First dim is batch size, second is length (going to be overwritten to max)\n",
    "        size_tuple = stream[0].shape[1:]\n",
    "        data_tensor = np.ones((num_items, max_len) + size_tuple, dtype='float32') * fill\n",
    "        mask_tensor = np.zeros((num_items, max_len), dtype='float32')\n",
    "        for idx, item in enumerate(stream):\n",
    "            start_offset = 0\n",
    "            if len(item) <= max_len:\n",
    "                data_tensor[idx, start_offset:start_offset + len(item)] = item\n",
    "                mask_tensor[idx, start_offset:start_offset + len(item)] = 1.\n",
    "            else:\n",
    "                if len(item) < bias + max_len:\n",
    "                    data_tensor[idx, start_offset:start_offset + max_len] = item[-max_len:]  # TODO not general\n",
    "                    mask_tensor[idx, start_offset:start_offset + max_len] = 1.\n",
    "                else:\n",
    "                    data_tensor[idx, start_offset:start_offset + max_len] = item[\n",
    "                                                                            bias:bias + max_len]  # TODO not general\n",
    "                    mask_tensor[idx, start_offset:start_offset + max_len] = 1.\n",
    "        returned_streams.append(data_tensor)\n",
    "        returned_streams.append(mask_tensor)\n",
    "    return returned_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2857., 3800., 3576., 2580., 1673., 1026.,  370.,   93.,   21.,\n",
       "           4.]),\n",
       " array([  1. ,  12.3,  23.6,  34.9,  46.2,  57.5,  68.8,  80.1,  91.4,\n",
       "        102.7, 114. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d107e0d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = []\n",
    "for subset in ['train', 'test']:\n",
    "    for k, v in DATASET[subset].items():\n",
    "        for _v in v:\n",
    "            lens.append(_v.shape[0])\n",
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "DATASET = {'train': {}, 'test': {}}\n",
    "\n",
    "for subset, s in zip(['train', 'test'], [all_sep_spk, all_sep_spk_test]):\n",
    "    keys = ALL_LBL[subset]\n",
    "    for k, v in zip(keys, s):\n",
    "        if k not in DATASET[subset]:\n",
    "            DATASET[subset][k] = []\n",
    "        DATASET[subset][k].append(v.T)\n",
    "\n",
    "for subset in ['train', 'test']:\n",
    "    for k, v in DATASET[subset].iteritems():\n",
    "        DATASET[subset][k] = pad_streams([np.array(v).T], 80)[0]\n",
    "# check\n",
    "print len(DATASET['train'])\n",
    "print len(DATASET['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "test_keys = DATASET['test'].keys()\n",
    "for i in range(63):\n",
    "    k = test_keys[i]\n",
    "    DATASET['train'][k] = DATASET['test'][k]\n",
    "    del DATASET['test'][k]\n",
    "\n",
    "print len(DATASET['train'])\n",
    "print len(DATASET['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 80, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b3f8026d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b3f9dc790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print DATASET['train'][4].shape\n",
    "\n",
    "f, ax = plt.subplots(2, 2)\n",
    "ax[0][0].imshow(DATASET['train'][4][0], aspect='auto')\n",
    "ax[1][0].imshow(DATASET['train'][5][0], aspect='auto')\n",
    "ax[0][1].imshow(DATASET['train'][6][0], aspect='auto')\n",
    "ax[1][1].imshow(DATASET['train'][7][0], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         1196096     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,200,193\n",
      "Trainable params: 1,200,193\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D, Masking\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = (None, 64)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "leg = Sequential()\n",
    "leg.add(Masking(mask_value=-1.0, input_shape=input_shape))\n",
    "leg.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "leg.add(Bidirectional(LSTM(100)))\n",
    "leg.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-6),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "# leg.add(Dense(512,activation=\"sigmoid\"))\n",
    "\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = leg(left_input)\n",
    "encoded_r = leg(right_input)\n",
    "#merge two encoded inputs with the l1 distance between them\n",
    "both = Lambda(lambda x: K.abs(x[0]-x[1]))([encoded_l,encoded_r])\n",
    "prediction = Dense(1, activation='sigmoid', bias_initializer=b_init)(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
    "#optimizer = SGD(0.0004,momentum=0.6,nesterov=True,decay=0.0003)\n",
    "\n",
    "optimizer = Adam()\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['acc'])\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_Loader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    def __init__(self, x):\n",
    "        self.x = x \n",
    "        self.classes_train = x['train'].keys()\n",
    "        self.classes_test = x['test'].keys()\n",
    "\n",
    "    def get_batch(self, n):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        categories = rng.choice(self.classes_train, size=(n,), replace=False)\n",
    "        pairs = [np.zeros((n, 80, 64)) for i in range(2)]\n",
    "        targets = np.zeros((n,))\n",
    "        targets[n//2:] = 1\n",
    "        for i in range(n):\n",
    "            category = categories[i]\n",
    "            idx_1 = rng.randint(0, len(self.x['train'][category]))\n",
    "            pairs[0][i,:,:] = self.x['train'][category][idx_1]\n",
    "            \n",
    "            #pick images of same class for 1st half, different for 2nd\n",
    "            category_2 = category if i >= n//2 else (category + rng.randint(1,len(self.classes_train))) % len(self.classes_train)\n",
    "            idx_2 = rng.randint(0, len(self.x['train'][category_2]))\n",
    "            pairs[1][i,:,:] = self.x['train'][category_2][idx_2]\n",
    "        return pairs, targets\n",
    "\n",
    "    def make_oneshot_task(self, N):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        categories = rng.choice(self.classes_test, size=(N,), replace=False)\n",
    "        true_category = categories[0]\n",
    "        ex1 = rng.randint(0, len(self.x['test'][true_category]))\n",
    "        \n",
    "        ex2 = rng.randint(0, len(self.x['test'][true_category]))\n",
    "        while ex2 == ex1:\n",
    "            ex2 = rng.randint(0, len(self.x['test'][true_category]))\n",
    "        \n",
    "        test_image = np.asarray([self.x['test'][true_category][ex1]]*N).reshape(N, 80, 64)\n",
    "        \n",
    "        support_set = np.asarray([self.x['test'][c][rng.randint(0, len(self.x['test'][c]))] for c in categories])\n",
    "        support_set[0,:,:] = self.x['test'][true_category][ex2]\n",
    "        \n",
    "        pairs = [test_image,support_set]\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        return pairs, targets\n",
    "\n",
    "    def test_oneshot(self,model,N,k,verbose=0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        pass\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} unique {} way one-shot learning tasks ...\".format(k,N))\n",
    "        for i in tqdm(range(k)):\n",
    "            inputs, targets = self.make_oneshot_task(N)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == 0:\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, training loss: 0.70, training acc: 0.52\n",
      "iteration 20, training loss: 0.69, training acc: 0.52\n",
      "iteration 30, training loss: 0.68, training acc: 0.57\n",
      "iteration 40, training loss: 0.67, training acc: 0.58\n",
      "iteration 50, training loss: 0.70, training acc: 0.50\n",
      "iteration 60, training loss: 0.69, training acc: 0.63\n",
      "iteration 70, training loss: 0.67, training acc: 0.56\n",
      "iteration 80, training loss: 0.70, training acc: 0.53\n",
      "iteration 90, training loss: 0.66, training acc: 0.62\n",
      "iteration 100, training loss: 0.67, training acc: 0.57\n",
      "iteration 110, training loss: 0.67, training acc: 0.56\n",
      "iteration 120, training loss: 0.68, training acc: 0.57\n",
      "iteration 130, training loss: 0.71, training acc: 0.55\n",
      "iteration 140, training loss: 0.67, training acc: 0.57\n",
      "iteration 150, training loss: 0.67, training acc: 0.61\n",
      "iteration 160, training loss: 0.66, training acc: 0.58\n",
      "iteration 170, training loss: 0.67, training acc: 0.55\n",
      "iteration 180, training loss: 0.68, training acc: 0.52\n",
      "iteration 190, training loss: 0.63, training acc: 0.64\n",
      "iteration 200, training loss: 0.68, training acc: 0.56\n",
      "iteration 210, training loss: 0.63, training acc: 0.61\n",
      "iteration 220, training loss: 0.66, training acc: 0.61\n",
      "iteration 230, training loss: 0.68, training acc: 0.55\n",
      "iteration 240, training loss: 0.66, training acc: 0.56\n",
      "iteration 250, training loss: 0.67, training acc: 0.56\n",
      "iteration 260, training loss: 0.66, training acc: 0.56\n",
      "iteration 270, training loss: 0.63, training acc: 0.64\n",
      "iteration 280, training loss: 0.61, training acc: 0.72\n",
      "iteration 290, training loss: 0.67, training acc: 0.58\n",
      "iteration 300, training loss: 0.64, training acc: 0.65\n",
      "iteration 310, training loss: 0.68, training acc: 0.55\n",
      "iteration 320, training loss: 0.68, training acc: 0.52\n",
      "iteration 330, training loss: 0.65, training acc: 0.58\n",
      "iteration 340, training loss: 0.66, training acc: 0.57\n",
      "iteration 350, training loss: 0.67, training acc: 0.60\n",
      "iteration 360, training loss: 0.63, training acc: 0.61\n",
      "iteration 370, training loss: 0.60, training acc: 0.70\n",
      "iteration 380, training loss: 0.65, training acc: 0.61\n",
      "iteration 390, training loss: 0.68, training acc: 0.55\n",
      "iteration 400, training loss: 0.60, training acc: 0.69\n",
      "iteration 410, training loss: 0.65, training acc: 0.62\n",
      "iteration 420, training loss: 0.64, training acc: 0.64\n",
      "iteration 430, training loss: 0.66, training acc: 0.59\n",
      "iteration 440, training loss: 0.63, training acc: 0.63\n",
      "iteration 450, training loss: 0.67, training acc: 0.64\n",
      "iteration 460, training loss: 0.63, training acc: 0.61\n",
      "iteration 470, training loss: 0.65, training acc: 0.58\n",
      "iteration 480, training loss: 0.62, training acc: 0.67\n",
      "iteration 490, training loss: 0.64, training acc: 0.65\n",
      "iteration 500, training loss: 0.68, training acc: 0.60\n",
      "iteration 510, training loss: 0.63, training acc: 0.65\n",
      "iteration 520, training loss: 0.64, training acc: 0.66\n",
      "iteration 530, training loss: 0.68, training acc: 0.56\n",
      "iteration 540, training loss: 0.66, training acc: 0.62\n",
      "iteration 550, training loss: 0.66, training acc: 0.62\n",
      "iteration 560, training loss: 0.69, training acc: 0.57\n",
      "iteration 570, training loss: 0.57, training acc: 0.73\n"
     ]
    }
   ],
   "source": [
    "evaluate_every = 7000\n",
    "loss_every = 10\n",
    "batch_size = 100\n",
    "N_way = 2\n",
    "n_val = 550\n",
    "# siamese_net.load_weights(\"PATH\")\n",
    "loader = Siamese_Loader(DATASET)\n",
    "\n",
    "best = 76.0\n",
    "\n",
    "for i in range(900000):\n",
    "    (inputs,targets) = loader.get_batch(batch_size)\n",
    "    loss = siamese_net.train_on_batch(inputs, targets)\n",
    "    if i % loss_every == 0 and i != 0:\n",
    "        print(\"iteration {}, training loss: {:.2f}, training acc: {:.2f}\".format(i,loss[0],loss[1]))\n",
    "    if i % evaluate_every == 0 and i != 0:\n",
    "        val_acc = loader.test_oneshot(siamese_net,N_way,n_val,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"saving {}\".format(val_acc))\n",
    "            siamese_net.save('PATH')\n",
    "            best=val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
